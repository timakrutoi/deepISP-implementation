{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d9539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for correct pytorch version\n",
    "# import pkg_resources\n",
    "# pkg_resources.require(\"torch==1.11.0\")\n",
    "# pkg_resources.require(\"torchmetrics==0.11.0\")\n",
    "\n",
    "# main net\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "# ====================================== #\n",
    "\n",
    "# for dataset\n",
    "from os import listdir, sep\n",
    "\n",
    "from torchvision import transforms\n",
    "# from torchvision.io import read_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# loading raw image\n",
    "from skimage import io\n",
    "\n",
    "# demosaicing raw image\n",
    "from colour_demosaicing import demosaicing_CFA_Bayer_bilinear\n",
    "# ====================================== #\n",
    "\n",
    "# for loss and optimizer\n",
    "import torch.optim as optim\n",
    "from kornia.color import rgb_to_lab\n",
    "from torchmetrics import MultiScaleStructuralSimilarityIndexMeasure as MSSSIM\n",
    "# ====================================== #\n",
    "\n",
    "# quality of life\n",
    "from tqdm import tqdm\n",
    "# ====================================== #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327b363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepispLL(nn.Module):\n",
    "    def __init__(self, kernel=(3,3), stride=1, padding=1):\n",
    "        super(DeepispLL, self).__init__()\n",
    "\n",
    "        # self.size = n * m\n",
    "        self.padding = padding\n",
    "        self.kernel = kernel\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        rh = nn.Conv2d(61, 61, kernel_size=self.kernel, stride=self.stride, padding=self.padding)(x[:,:61,:,:])\n",
    "        rh = nn.ReLU()(rh)\n",
    "\n",
    "        lh = nn.Conv2d(3, 3, kernel_size=self.kernel, stride=self.stride, padding=self.padding)(x[:,61:,:,:])\n",
    "        lh = nn.Tanh()(lh)\n",
    "\n",
    "        # need to so some sum\n",
    "        # lh += x\n",
    "\n",
    "        return torch.cat((rh, lh), 1)\n",
    "\n",
    "\n",
    "class DeepispHL(nn.Module):\n",
    "    def __init__(self, kernel=(3,3), stride=2, padding=1):\n",
    "        super(DeepispHL, self).__init__()\n",
    "\n",
    "        self.padding = padding\n",
    "        self.kernel = kernel\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.Conv2d(64, 64, kernel_size=self.kernel, stride=self.stride, padding=self.padding)(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = nn.MaxPool2d(2, 2)(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GlobalPool2d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalPool2d, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, w, h = tuple(x.shape)\n",
    "        return nn.AvgPool2d(kernel_size=(h,w))(x).reshape((b, c))\n",
    "\n",
    "\n",
    "def triu(rgb):\n",
    "    res = torch.tensor(np.empty(10), dtype=torch.float)\n",
    "    r, g, b = rgb[0, 0], rgb[0, 1], rgb[0, 2]\n",
    "    res[0] = r*r\n",
    "    res[1] = r*g\n",
    "    res[2] = r*b\n",
    "    res[3] = r\n",
    "    res[4] = g*g\n",
    "    res[5] = g*b\n",
    "    res[6] = g\n",
    "    res[7] = b*b\n",
    "    res[8] = b\n",
    "    res[9] = 1\n",
    "\n",
    "    return res.reshape((10))\n",
    "\n",
    "\n",
    "def Tform(I, W):\n",
    "    b, c, h, w = I.shape\n",
    "    res = torch.tensor(np.empty(I.shape))\n",
    "    W = W.reshape((3, 10))\n",
    "    for x in range(h):\n",
    "        for y in range(w):\n",
    "            res[:, :, x, y] = W @ triu(I[:, :, x, y])\n",
    "    return res\n",
    "\n",
    "\n",
    "class DeepISP(nn.Module):\n",
    "    def __init__(self, n_ll, n_hl, stride=1, padding=1):\n",
    "        super(DeepISP, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        \n",
    "        self.lowlevel = nn.Sequential()\n",
    "        self.highlevel = nn.Sequential()\n",
    "\n",
    "        self.lowlevel.append(nn.Conv2d(3, 64, kernel_size=(3,3), stride=self.stride, padding=self.padding))\n",
    "        self.highlevel.append(nn.Conv2d(61, 64, kernel_size=(3,3), stride=self.stride, padding=self.padding))\n",
    "\n",
    "        for i in range(n_ll):\n",
    "            self.lowlevel.append(DeepispLL(stride=self.stride, padding=self.padding))\n",
    "\n",
    "        for i in range(n_hl):\n",
    "            self.highlevel.append(DeepispHL(stride=self.stride, padding=self.padding))\n",
    "\n",
    "        # append global pooling on high level to get 1x1x64 shape\n",
    "        # current shape = (N/4^n_hl)*(M/4^n_hl)*64\n",
    "        # self.highlevel.append(nn.MaxPool2(...))\n",
    "        self.highlevel.append(GlobalPool2d())\n",
    "\n",
    "        self.highlevel.append(nn.Linear(64, 30))\n",
    "        \n",
    "        # do some T(W, L)\n",
    "        self.T = Tform\n",
    "    \n",
    "    def forward(self, x):\n",
    "        I = self.lowlevel(x)\n",
    "        W = self.highlevel(I[:,:61,:,:])\n",
    "        return self.T(I[:,61:,:,:], W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb61e504",
   "metadata": {},
   "outputs": [],
   "source": [
    "class S7Dataset(Dataset):\n",
    "    def __init__(self, directory, mode, target, factor, crop_size):\n",
    "        self.directory = directory\n",
    "\n",
    "        self.raw_transform = demosaicing_CFA_Bayer_bilinear\n",
    "        self.crop_size = crop_size\n",
    "\n",
    "        self.dng = '.dng'\n",
    "        self.jpg = '.jpg'\n",
    "\n",
    "        self.l = len(listdir(self.directory))\n",
    "\n",
    "        if mode == 'train':\n",
    "            self.len = 0, int(self.l * factor)\n",
    "        if mode == 'test':\n",
    "            self.len = int(self.l * factor), self.l\n",
    "\n",
    "        if target == 'm':\n",
    "            self.target = 'medium_exposure'\n",
    "        elif target == 's':\n",
    "            self.target = 'short_exposure'\n",
    "            self.jpg = '1.jpg'\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return self.len[1] - self.len[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        l = listdir(self.directory)\n",
    "\n",
    "        i_img = io.imread(sep.join([self.directory, l[idx + self.len[0]], f'{self.target}{self.dng}']))\n",
    "        o_img = io.imread(sep.join([self.directory, l[idx + self.len[0]], f'{self.target}{self.jpg}']))\n",
    "\n",
    "        i_img = self.raw_transform(i_img) / 1024\n",
    "        \n",
    "        old_shape = i_img.shape\n",
    "        new_shape = old_shape[2], self.crop_size, self.crop_size\n",
    "        \n",
    "        x = np.random.randint(0, old_shape[0] - self.crop_size)\n",
    "        y = np.random.randint(0, old_shape[1] - self.crop_size)\n",
    "        \n",
    "        i_img = torch.tensor(i_img[x:x+self.crop_size, y:y+self.crop_size, :])\n",
    "        o_img = torch.tensor(o_img[x:x+self.crop_size, y:y+self.crop_size, :])\n",
    "                \n",
    "        i_img = i_img.reshape(new_shape)\n",
    "        o_img = o_img.reshape(new_shape)\n",
    "        \n",
    "        # maybe do data normalization\n",
    "        # img = norm(img)\n",
    "\n",
    "        return i_img.float(), o_img.float()\n",
    "\n",
    "\n",
    "def get_data(data_path, batch_size, target='m', factor=0.7, crop_size=256):\n",
    "    train_data = S7Dataset(\n",
    "        directory=data_path,\n",
    "        mode='train',\n",
    "        target=target,\n",
    "        factor=factor,\n",
    "        crop_size=crop_size\n",
    "    )\n",
    "\n",
    "    test_data = S7Dataset(\n",
    "        directory=data_path,\n",
    "        mode='test',\n",
    "        target=target,\n",
    "        factor=factor,\n",
    "        crop_size=crop_size\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_data,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bd69b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class deepISPloss():\n",
    "    def __init__(self, alpha=0.5):\n",
    "        self.alpha = alpha\n",
    "        self.MSSSIM = MSSSIM()\n",
    "    \n",
    "    def __call__(self, x, target):\n",
    "        lab_x = rgb_to_lab(x).float()\n",
    "        lab_tar = rgb_to_lab(target).float()\n",
    "        b, c, h, w = lab_x.shape\n",
    "\n",
    "        res = (1 - self.alpha) * torch.mean(torch.abs(lab_x - lab_tar))\n",
    "        # take only first channel to MS-SSIM\n",
    "        res +=     self.alpha  * (self.MSSSIM(lab_x[:, :1, :, :], lab_tar[:, :1, :, :]))\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b77b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/jupyter/mnt/datasets/S7Dataset/S7-ISP-Dataset'\n",
    "train, test = get_data(data_path, batch_size=1)\n",
    "\n",
    "print(f'train batch number {len(train)}')\n",
    "print(f'test  batch number {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aead0e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = 1\n",
    "lr = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "make_checkpoints = True\n",
    "checkpoint_path = '/home/jupyter/work/resources/deepISP-implementation/checkp'\n",
    "\n",
    "epochs = [i for i in range(e)]\n",
    "\n",
    "model = DeepISP(0, 0).float()\n",
    "criterion = deepISPloss()\n",
    "optimizer = optim.SGD(DeepISP.parameters(model), lr, momentum)\n",
    "\n",
    "test_loss = 0\n",
    "\n",
    "print('Starting trainig...')\n",
    "\n",
    "for epoch in epochs:\n",
    "    train_iter = tqdm(train, ncols=100, desc='Epoch: {}, training'.format(epoch))\n",
    "    for (x, target) in train_iter:\n",
    "        optimizer.zero_grad()\n",
    "        y = model(x.float())\n",
    "        loss = criterion(y, target)\n",
    "\n",
    "#         loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    test_iter = tqdm(test, ncols=128, desc='Epoch: {}, testing '.format(epoch))\n",
    "    for idx, (x, target) in enumerate(test_iter):\n",
    "        y = model(x)\n",
    "        loss = criterion(y, target)\n",
    "        test_loss += loss\n",
    "        test_iter.set_postfix(str=f'loss: {test_loss / (idx + 1)}')\n",
    "    test_loss /= len(test_iter)\n",
    "\n",
    "print('Training done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2118490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'epoch': 0,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': test_loss,\n",
    "}, checkpoint_path + '/model_e{}_loss{}'.format(epoch, test_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
