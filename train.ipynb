{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8530f7d7-9d8e-46e7-9e07-b091aff4b07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from dataset import get_data\n",
    "from network import DeepISP\n",
    "from loss import deepISPloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76df0c5e-9dc4-4b0c-9b45-a53262ba1808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = '/home/jupyter/mnt/datasets/S7Dataset/S7-ISP-Dataset'\n",
    "data_path = '/home/tima/projects/isp/dataset/S7-ISP-Dataset'\n",
    "train, test = get_data(data_path, batch_size=1, crop_size=256)\n",
    "\n",
    "print(f'train batch number {len(train)}')\n",
    "print(f'test  batch number {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0081a74-948e-4f9a-978d-ba63c57607f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions:\n",
    "# - sum in low level\n",
    "\n",
    "start_epoch = 0\n",
    "e = 100\n",
    "lr = 10e-5\n",
    "momentum = 0.9\n",
    "betas = (0.9, 0.999)\n",
    "\n",
    "make_checkpoints = True\n",
    "checkpoint_path = '/home/jupyter/work/resources/deepISP-implementation/checkp/15-3m'\n",
    "# checkpoint_path = '/home/tima/projects/isp/deepisp/CP'\n",
    "\n",
    "epochs = [i for i in range(start_epoch, e)]\n",
    "\n",
    "# we can create any number of low level layers\n",
    "# but we can create limited number of high level layers\n",
    "# its because we do pool(2, 2) in every hl layer\n",
    "# so we can create maximum hlc = log2(img_size)\n",
    "# assuming image is a squire matrix with height = width = img_size\n",
    "llc, hlc = 15, 3\n",
    "model = DeepISP(llc, hlc).float()\n",
    "criterion = deepISPloss()\n",
    "# optimizer = optim.SGD(DeepISP.parameters(model), lr, momentum)\n",
    "optimizer = optim.Adam(DeepISP.parameters(model), lr, betas)\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "if start_epoch > 0:\n",
    "    dirs = listdir(checkpoint_path)\n",
    "    cp = [i for i in dirs if f'_e{start_epoch - 1}_' in i]\n",
    "    checkpoint = torch.load(sep.join([checkpoint_path, cp[0]]))\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71925cf-12ca-4f86-9445-2909d03423eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting trainig...')\n",
    "\n",
    "for epoch in epochs:\n",
    "    train_iter = tqdm(train, ncols=100, desc='Epoch: {}, training'.format(epoch))\n",
    "    for (x, target) in train_iter:\n",
    "        optimizer.zero_grad()\n",
    "        y = model(x.float())\n",
    "        loss = criterion(y, target)\n",
    "        loss.requires_grad_()\n",
    "        \n",
    "        # print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_iter.close()\n",
    "    \n",
    "    test_iter = tqdm(test, ncols=128, desc='Epoch: {}, testing '.format(epoch))\n",
    "    for idx, (x, target) in enumerate(test_iter):\n",
    "        y = model(x)\n",
    "        loss = criterion(y, target)\n",
    "        test_loss += loss\n",
    "        test_iter.set_postfix(str=f'loss: {test_loss / (idx + 1)}')\n",
    "    test_loss /= len(test_iter)\n",
    "    test_iter.close()\n",
    "    \n",
    "    if make_checkpoints:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': test_loss,\n",
    "        }, checkpoint_path + '/model{}-{}_e{}_loss{}'.format(llc, hlc, epoch, test_loss))\n",
    "\n",
    "print('Training done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
