{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8530f7d7-9d8e-46e7-9e07-b091aff4b07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from os import listdir, sep\n",
    "\n",
    "from dataset import get_data\n",
    "from network import DeepISP\n",
    "from loss import deepISPloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb1f263-96e3-416c-86dc-ea6e0c2f1383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil, os\n",
    "process = psutil.Process(os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76df0c5e-9dc4-4b0c-9b45-a53262ba1808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = '/home/jupyter/mnt/datasets/S7Dataset/S7-ISP-Dataset'\n",
    "data_path = '/home/tima/projects/isp/dataset/S7-ISP-Dataset'\n",
    "train, test = get_data(data_path, batch_size=1, crop_size=256, norm=True)\n",
    "\n",
    "print(f'train batch number {len(train)}')\n",
    "print(f'test  batch number {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0081a74-948e-4f9a-978d-ba63c57607f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "e = 100\n",
    "test_every_n = 1\n",
    "\n",
    "lr = 5 * 10e-5\n",
    "momentum = 0.9\n",
    "betas = (0.9, 0.999)\n",
    "\n",
    "make_checkpoints = True\n",
    "# checkpoint_path = '/home/jupyter/work/resources/deepISP-implementation/checkp/15-3m'\n",
    "checkpoint_path = '/home/tima/projects/isp/deepisp/CP/'\n",
    "\n",
    "epochs = [i for i in range(start_epoch, e)]\n",
    "\n",
    "# we can create any number of low level layers\n",
    "# but we can create limited number of high level layers\n",
    "# its because we do pool(2, 2) in every hl layer\n",
    "# so we can create maximum hlc = log2(img_size)\n",
    "# assuming image is a squire matrix with height = width = img_size\n",
    "llc, hlc = 15, 3\n",
    "model = DeepISP(llc, hlc).float()\n",
    "criterion = deepISPloss()\n",
    "optimizer = optim.Adam(DeepISP.parameters(model), lr, betas)\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "if start_epoch > 0:\n",
    "    dirs = listdir(checkpoint_path)\n",
    "    cp = [i for i in dirs if f'_e{start_epoch - 1}_' in i]\n",
    "    checkpoint = torch.load(sep.join([checkpoint_path, cp[0]]))\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71925cf-12ca-4f86-9445-2909d03423eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Starting trainig...')\n",
    "\n",
    "for epoch in epochs:\n",
    "    train_iter = tqdm(train, ncols=150, desc='Epoch: {}, training'.format(epoch))\n",
    "    for idx, (x, target) in enumerate(train_iter):\n",
    "        optimizer.zero_grad()\n",
    "        y = model(x.float())\n",
    "        # print(y.min(), y.max())\n",
    "        loss = criterion(y, target.float())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_iter.set_postfix(str=f'mem: {round(process.memory_info().rss / (2 ** 20), 2)}mb')\n",
    "    train_iter.close()\n",
    "\n",
    "    # skipping testing and saving checkpoints for some epochs\n",
    "    if epoch % test_every_n != 0:\n",
    "        continue\n",
    "\n",
    "    test_loss = []\n",
    "    test_iter = tqdm(test, ncols=150, desc='Epoch: {}, testing '.format(epoch))\n",
    "    for idx, (x, target) in enumerate(test_iter):\n",
    "        y = model(x.float())\n",
    "        loss = criterion(y, target.float())\n",
    "\n",
    "        test_loss.append(loss.item())\n",
    "        test_iter.set_postfix(str=f'mem: {round(process.memory_info().rss / (2 ** 20), 2)}mb, ' +\n",
    "                                  f'loss: {round(np.mean(test_loss), 2)}')\n",
    "    test_iter.close()\n",
    "\n",
    "    if make_checkpoints:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': np.mean(test_loss),\n",
    "        }, checkpoint_path + '/model{}-{}_e{}_loss{}'.format(llc, hlc, epoch, round(np.mean(test_loss), 2)))\n",
    "\n",
    "print('Training done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
